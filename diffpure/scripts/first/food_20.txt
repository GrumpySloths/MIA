Logging to /tmp/openai-2023-01-08-11-05-47-568562
creating model and diffusion...
creating data loader...
training...
----------------------------
| grad_norm     | 1.16e+03 |
| lg_loss_scale | 20       |
| loss          | 1.03     |
| loss_q0       | 1.07     |
| loss_q1       | 1.01     |
| loss_q2       | 1.01     |
| loss_q3       | 1.01     |
| mse           | 1        |
| mse_q0        | 1        |
| mse_q1        | 1        |
| mse_q2        | 1        |
| mse_q3        | 1        |
| param_norm    | 347      |
| samples       | 256      |
| step          | 0        |
| vb            | 0.0254   |
| vb_q0         | 0.07     |
| vb_q1         | 0.00739  |
| vb_q2         | 0.00944  |
| vb_q3         | 0.0128   |
----------------------------
saving model 0...
saving model 0.9999...
Found NaN, decreased lg_loss_scale to 19.001
Found NaN, decreased lg_loss_scale to 18.002000000000002
Found NaN, decreased lg_loss_scale to 17.003000000000004
----------------------------
| grad_norm     | 1.15e+03 |
| lg_loss_scale | 17.9     |
| loss          | 0.896    |
| loss_q0       | 0.933    |
| loss_q1       | 0.882    |
| loss_q2       | 0.881    |
| loss_q3       | 0.887    |
| mse           | 0.882    |
| mse_q0        | 0.904    |
| mse_q1        | 0.875    |
| mse_q2        | 0.873    |
| mse_q3        | 0.876    |
| param_norm    | 347      |
| samples       | 2.82e+03 |
| step          | 10       |
| vb            | 0.0136   |
| vb_q0         | 0.0286   |
| vb_q1         | 0.00648  |
| vb_q2         | 0.00819  |
| vb_q3         | 0.0113   |
----------------------------
Found NaN, decreased lg_loss_scale to 16.011000000000013
Found NaN, decreased lg_loss_scale to 15.011000000000013
----------------------------
| grad_norm     | 978      |
| lg_loss_scale | 15.9     |
| loss          | 0.599    |
| loss_q0       | 0.661    |
| loss_q1       | 0.577    |
| loss_q2       | 0.581    |
| loss_q3       | 0.578    |
| mse           | 0.588    |
| mse_q0        | 0.631    |
| mse_q1        | 0.572    |
| mse_q2        | 0.575    |
| mse_q3        | 0.571    |
| param_norm    | 347      |
| samples       | 5.38e+03 |
| step          | 20       |
| vb            | 0.0119   |
| vb_q0         | 0.0301   |
| vb_q1         | 0.00423  |
| vb_q2         | 0.00541  |
| vb_q3         | 0.00733  |
----------------------------
----------------------------
| grad_norm     | 725      |
| lg_loss_scale | 15       |
| loss          | 0.34     |
| loss_q0       | 0.414    |
| loss_q1       | 0.313    |
| loss_q2       | 0.315    |
| loss_q3       | 0.317    |
| mse           | 0.332    |
| mse_q0        | 0.391    |
| mse_q1        | 0.311    |
| mse_q2        | 0.312    |
| mse_q3        | 0.313    |
| param_norm    | 347      |
| samples       | 7.94e+03 |
| step          | 30       |
| vb            | 0.00803  |
| vb_q0         | 0.0225   |
| vb_q1         | 0.0023   |
| vb_q2         | 0.00291  |
| vb_q3         | 0.00399  |
----------------------------
----------------------------
| grad_norm     | 457      |
| lg_loss_scale | 15       |
| loss          | 0.159    |
| loss_q0       | 0.241    |
| loss_q1       | 0.139    |
| loss_q2       | 0.13     |
| loss_q3       | 0.127    |
| mse           | 0.152    |
| mse_q0        | 0.218    |
| mse_q1        | 0.138    |
| mse_q2        | 0.129    |
| mse_q3        | 0.126    |
| param_norm    | 347      |
| samples       | 1.05e+04 |
| step          | 40       |
| vb            | 0.00672  |
| vb_q0         | 0.0237   |
| vb_q1         | 0.00102  |
| vb_q2         | 0.0012   |
| vb_q3         | 0.00162  |
----------------------------
----------------------------
| grad_norm     | 248      |
| lg_loss_scale | 15       |
| loss          | 0.0688   |
| loss_q0       | 0.145    |
| loss_q1       | 0.0487   |
| loss_q2       | 0.042    |
| loss_q3       | 0.0402   |
| mse           | 0.066    |
| mse_q0        | 0.135    |
| mse_q1        | 0.0484   |
| mse_q2        | 0.0416   |
| mse_q3        | 0.0397   |
| param_norm    | 347      |
| samples       | 1.31e+04 |
| step          | 50       |
| vb            | 0.00278  |
| vb_q0         | 0.00994  |
| vb_q1         | 0.000359 |
| vb_q2         | 0.000392 |
| vb_q3         | 0.00051  |
----------------------------
----------------------------
| grad_norm     | 122      |
| lg_loss_scale | 15.1     |
| loss          | 0.0418   |
| loss_q0       | 0.118    |
| loss_q1       | 0.0218   |
| loss_q2       | 0.0126   |
| loss_q3       | 0.0114   |
| mse           | 0.0365   |
| mse_q0        | 0.0972   |
| mse_q1        | 0.0217   |
| mse_q2        | 0.0125   |
| mse_q3        | 0.0112   |
| param_norm    | 347      |
| samples       | 1.56e+04 |
| step          | 60       |
| vb            | 0.00534  |
| vb_q0         | 0.0203   |
| vb_q1         | 0.000162 |
| vb_q2         | 0.000117 |
| vb_q3         | 0.000145 |
----------------------------
----------------------------
| grad_norm     | 84.5     |
| lg_loss_scale | 15.1     |
| loss          | 0.0327   |
| loss_q0       | 0.104    |
| loss_q1       | 0.0163   |
| loss_q2       | 0.00769  |
| loss_q3       | 0.00593  |
| mse           | 0.0294   |
| mse_q0        | 0.0906   |
| mse_q1        | 0.0162   |
| mse_q2        | 0.00762  |
| mse_q3        | 0.00586  |
| param_norm    | 347      |
| samples       | 1.82e+04 |
| step          | 70       |
| vb            | 0.00333  |
| vb_q0         | 0.0136   |
| vb_q1         | 0.000121 |
| vb_q2         | 7.06e-05 |
| vb_q3         | 7.49e-05 |
----------------------------
----------------------------
| grad_norm     | 69.5     |
| lg_loss_scale | 15.1     |
| loss          | 0.0309   |
| loss_q0       | 0.0981   |
| loss_q1       | 0.015    |
| loss_q2       | 0.00647  |
| loss_q3       | 0.00472  |
| mse           | 0.028    |
| mse_q0        | 0.0865   |
| mse_q1        | 0.0149   |
| mse_q2        | 0.00641  |
| mse_q3        | 0.00466  |
| param_norm    | 347      |
| samples       | 2.07e+04 |
| step          | 80       |
| vb            | 0.00293  |
| vb_q0         | 0.0116   |
| vb_q1         | 0.000111 |
| vb_q2         | 5.94e-05 |
| vb_q3         | 5.96e-05 |
----------------------------
----------------------------
| grad_norm     | 45.5     |
| lg_loss_scale | 15.1     |
| loss          | 0.0301   |
| loss_q0       | 0.0939   |
| loss_q1       | 0.014    |
| loss_q2       | 0.00555  |
| loss_q3       | 0.00383  |
| mse           | 0.0263   |
| mse_q0        | 0.0792   |
| mse_q1        | 0.0139   |
| mse_q2        | 0.0055   |
| mse_q3        | 0.00378  |
| param_norm    | 347      |
| samples       | 2.33e+04 |
| step          | 90       |
| vb            | 0.00386  |
| vb_q0         | 0.0147   |
| vb_q1         | 0.000104 |
| vb_q2         | 5.06e-05 |
| vb_q3         | 4.84e-05 |
----------------------------
----------------------------
| grad_norm     | 50.3     |
| lg_loss_scale | 15.1     |
| loss          | 0.0269   |
| loss_q0       | 0.0917   |
| loss_q1       | 0.0129   |
| loss_q2       | 0.00488  |
| loss_q3       | 0.00327  |
| mse           | 0.0237   |
| mse_q0        | 0.0783   |
| mse_q1        | 0.0128   |
| mse_q2        | 0.00484  |
| mse_q3        | 0.00323  |
| param_norm    | 347      |
| samples       | 2.59e+04 |
| step          | 100      |
| vb            | 0.00321  |
| vb_q0         | 0.0134   |
| vb_q1         | 9.52e-05 |
| vb_q2         | 4.46e-05 |
| vb_q3         | 4.12e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 109      |
| lg_loss_scale | 15.1     |
| loss          | 0.0299   |
| loss_q0       | 0.0974   |
| loss_q1       | 0.0128   |
| loss_q2       | 0.00517  |
| loss_q3       | 0.00362  |
| mse           | 0.0255   |
| mse_q0        | 0.0803   |
| mse_q1        | 0.0127   |
| mse_q2        | 0.00512  |
| mse_q3        | 0.00358  |
| param_norm    | 347      |
| samples       | 2.84e+04 |
| step          | 110      |
| vb            | 0.00434  |
| vb_q0         | 0.0171   |
| vb_q1         | 9.45e-05 |
| vb_q2         | 4.74e-05 |
| vb_q3         | 4.6e-05  |
----------------------------
----------------------------
| grad_norm     | 55       |
| lg_loss_scale | 15.1     |
| loss          | 0.0236   |
| loss_q0       | 0.0755   |
| loss_q1       | 0.0122   |
| loss_q2       | 0.00441  |
| loss_q3       | 0.00281  |
| mse           | 0.0217   |
| mse_q0        | 0.0681   |
| mse_q1        | 0.0121   |
| mse_q2        | 0.00437  |
| mse_q3        | 0.00277  |
| param_norm    | 347      |
| samples       | 3.1e+04  |
| step          | 120      |
| vb            | 0.00188  |
| vb_q0         | 0.00743  |
| vb_q1         | 9.02e-05 |
| vb_q2         | 4.03e-05 |
| vb_q3         | 3.55e-05 |
----------------------------
----------------------------
| grad_norm     | 66       |
| lg_loss_scale | 15.1     |
| loss          | 0.0279   |
| loss_q0       | 0.092    |
| loss_q1       | 0.0118   |
| loss_q2       | 0.00428  |
| loss_q3       | 0.00262  |
| mse           | 0.0232   |
| mse_q0        | 0.0736   |
| mse_q1        | 0.0117   |
| mse_q2        | 0.00424  |
| mse_q3        | 0.00259  |
| param_norm    | 347      |
| samples       | 3.35e+04 |
| step          | 130      |
| vb            | 0.00469  |
| vb_q0         | 0.0184   |
| vb_q1         | 8.69e-05 |
| vb_q2         | 3.89e-05 |
| vb_q3         | 3.33e-05 |
----------------------------
----------------------------
| grad_norm     | 68.8     |
| lg_loss_scale | 15.1     |
| loss          | 0.025    |
| loss_q0       | 0.0843   |
| loss_q1       | 0.0111   |
| loss_q2       | 0.00408  |
| loss_q3       | 0.00244  |
| mse           | 0.0212   |
| mse_q0        | 0.0688   |
| mse_q1        | 0.011    |
| mse_q2        | 0.00404  |
| mse_q3        | 0.00241  |
| param_norm    | 347      |
| samples       | 3.61e+04 |
| step          | 140      |
| vb            | 0.00381  |
| vb_q0         | 0.0154   |
| vb_q1         | 8.16e-05 |
| vb_q2         | 3.7e-05  |
| vb_q3         | 3.09e-05 |
----------------------------
----------------------------
| grad_norm     | 48.1     |
| lg_loss_scale | 15.1     |
| loss          | 0.0266   |
| loss_q0       | 0.0859   |
| loss_q1       | 0.011    |
| loss_q2       | 0.00363  |
| loss_q3       | 0.00204  |
| mse           | 0.0234   |
| mse_q0        | 0.0736   |
| mse_q1        | 0.0109   |
| mse_q2        | 0.0036   |
| mse_q3        | 0.00202  |
| param_norm    | 347      |
| samples       | 3.87e+04 |
| step          | 150      |
| vb            | 0.00324  |
| vb_q0         | 0.0122   |
| vb_q1         | 8.08e-05 |
| vb_q2         | 3.3e-05  |
| vb_q3         | 2.6e-05  |
----------------------------
----------------------------
| grad_norm     | 37.1     |
| lg_loss_scale | 15.2     |
| loss          | 0.0264   |
| loss_q0       | 0.0926   |
| loss_q1       | 0.0104   |
| loss_q2       | 0.00344  |
| loss_q3       | 0.00184  |
| mse           | 0.0214   |
| mse_q0        | 0.0723   |
| mse_q1        | 0.0103   |
| mse_q2        | 0.00341  |
| mse_q3        | 0.00181  |
| param_norm    | 347      |
| samples       | 4.12e+04 |
| step          | 160      |
| vb            | 0.00498  |
| vb_q0         | 0.0203   |
| vb_q1         | 7.68e-05 |
| vb_q2         | 3.11e-05 |
| vb_q3         | 2.32e-05 |
----------------------------
----------------------------
| grad_norm     | 95.6     |
| lg_loss_scale | 15.2     |
| loss          | 0.0231   |
| loss_q0       | 0.0751   |
| loss_q1       | 0.011    |
| loss_q2       | 0.0038   |
| loss_q3       | 0.00219  |
| mse           | 0.0203   |
| mse_q0        | 0.0641   |
| mse_q1        | 0.0109   |
| mse_q2        | 0.00376  |
| mse_q3        | 0.00216  |
| param_norm    | 347      |
| samples       | 4.38e+04 |
| step          | 170      |
| vb            | 0.00277  |
| vb_q0         | 0.011    |
| vb_q1         | 8.12e-05 |
| vb_q2         | 3.45e-05 |
| vb_q3         | 2.77e-05 |
----------------------------
----------------------------
| grad_norm     | 51.3     |
| lg_loss_scale | 15.2     |
| loss          | 0.0241   |
| loss_q0       | 0.0799   |
| loss_q1       | 0.0105   |
| loss_q2       | 0.00321  |
| loss_q3       | 0.00169  |
| mse           | 0.0211   |
| mse_q0        | 0.0683   |
| mse_q1        | 0.0104   |
| mse_q2        | 0.00319  |
| mse_q3        | 0.00167  |
| param_norm    | 347      |
| samples       | 4.63e+04 |
| step          | 180      |
| vb            | 0.00297  |
| vb_q0         | 0.0116   |
| vb_q1         | 7.74e-05 |
| vb_q2         | 2.91e-05 |
| vb_q3         | 2.13e-05 |
----------------------------
----------------------------
| grad_norm     | 41.8     |
| lg_loss_scale | 15.2     |
| loss          | 0.0244   |
| loss_q0       | 0.0798   |
| loss_q1       | 0.00992  |
| loss_q2       | 0.00298  |
| loss_q3       | 0.00144  |
| mse           | 0.0207   |
| mse_q0        | 0.0659   |
| mse_q1        | 0.00985  |
| mse_q2        | 0.00295  |
| mse_q3        | 0.00142  |
| param_norm    | 347      |
| samples       | 4.89e+04 |
| step          | 190      |
| vb            | 0.00367  |
| vb_q0         | 0.0139   |
| vb_q1         | 7.31e-05 |
| vb_q2         | 2.7e-05  |
| vb_q3         | 1.83e-05 |
----------------------------
----------------------------
| grad_norm     | 54.6     |
| lg_loss_scale | 15.2     |
| loss          | 0.0229   |
| loss_q0       | 0.0752   |
| loss_q1       | 0.00974  |
| loss_q2       | 0.00283  |
| loss_q3       | 0.00137  |
| mse           | 0.0195   |
| mse_q0        | 0.0621   |
| mse_q1        | 0.00966  |
| mse_q2        | 0.00281  |
| mse_q3        | 0.00135  |
| param_norm    | 347      |
| samples       | 5.15e+04 |
| step          | 200      |
| vb            | 0.00339  |
| vb_q0         | 0.0131   |
| vb_q1         | 7.19e-05 |
| vb_q2         | 2.57e-05 |
| vb_q3         | 1.72e-05 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 51.5     |
| lg_loss_scale | 15.2     |
| loss          | 0.0269   |
| loss_q0       | 0.0922   |
| loss_q1       | 0.0099   |
| loss_q2       | 0.00276  |
| loss_q3       | 0.0012   |
| mse           | 0.021    |
| mse_q0        | 0.0692   |
| mse_q1        | 0.00982  |
| mse_q2        | 0.00274  |
| mse_q3        | 0.00118  |
| param_norm    | 347      |
| samples       | 5.4e+04  |
| step          | 210      |
| vb            | 0.00586  |
| vb_q0         | 0.0229   |
| vb_q1         | 7.29e-05 |
| vb_q2         | 2.49e-05 |
| vb_q3         | 1.51e-05 |
----------------------------
----------------------------
| grad_norm     | 44.9     |
| lg_loss_scale | 15.2     |
| loss          | 0.0232   |
| loss_q0       | 0.0798   |
| loss_q1       | 0.00945  |
| loss_q2       | 0.00256  |
| loss_q3       | 0.00108  |
| mse           | 0.0195   |
| mse_q0        | 0.0651   |
| mse_q1        | 0.00938  |
| mse_q2        | 0.00254  |
| mse_q3        | 0.00106  |
| param_norm    | 347      |
| samples       | 5.66e+04 |
| step          | 220      |
| vb            | 0.00369  |
| vb_q0         | 0.0146   |
| vb_q1         | 6.98e-05 |
| vb_q2         | 2.32e-05 |
| vb_q3         | 1.36e-05 |
----------------------------
----------------------------
| grad_norm     | 28.8     |
| lg_loss_scale | 15.2     |
| loss          | 0.0241   |
| loss_q0       | 0.084    |
| loss_q1       | 0.0093   |
| loss_q2       | 0.00244  |
| loss_q3       | 0.000854 |
| mse           | 0.02     |
| mse_q0        | 0.0677   |
| mse_q1        | 0.00923  |
| mse_q2        | 0.00242  |
| mse_q3        | 0.000843 |
| param_norm    | 347      |
| samples       | 5.91e+04 |
| step          | 230      |
| vb            | 0.00412  |
| vb_q0         | 0.0163   |
| vb_q1         | 6.85e-05 |
| vb_q2         | 2.17e-05 |
| vb_q3         | 1.08e-05 |
----------------------------
----------------------------
| grad_norm     | 23.6     |
| lg_loss_scale | 15.2     |
| loss          | 0.0213   |
| loss_q0       | 0.0742   |
| loss_q1       | 0.00909  |
| loss_q2       | 0.00229  |
| loss_q3       | 0.000751 |
| mse           | 0.018    |
| mse_q0        | 0.0609   |
| mse_q1        | 0.00902  |
| mse_q2        | 0.00227  |
| mse_q3        | 0.000741 |
| param_norm    | 347      |
| samples       | 6.17e+04 |
| step          | 240      |
| vb            | 0.0033   |
| vb_q0         | 0.0133   |
| vb_q1         | 6.7e-05  |
| vb_q2         | 2.05e-05 |
| vb_q3         | 9.43e-06 |
----------------------------
----------------------------
| grad_norm     | 19       |
| lg_loss_scale | 15.2     |
| loss          | 0.0212   |
| loss_q0       | 0.0709   |
| loss_q1       | 0.00869  |
| loss_q2       | 0.00215  |
| loss_q3       | 0.000677 |
| mse           | 0.0178   |
| mse_q0        | 0.0578   |
| mse_q1        | 0.00863  |
| mse_q2        | 0.00213  |
| mse_q3        | 0.000669 |
| param_norm    | 347      |
| samples       | 6.43e+04 |
| step          | 250      |
| vb            | 0.00342  |
| vb_q0         | 0.0131   |
| vb_q1         | 6.41e-05 |
| vb_q2         | 1.92e-05 |
| vb_q3         | 8.51e-06 |
----------------------------
----------------------------
| grad_norm     | 16.6     |
| lg_loss_scale | 15.3     |
| loss          | 0.0195   |
| loss_q0       | 0.0676   |
| loss_q1       | 0.00863  |
| loss_q2       | 0.00214  |
| loss_q3       | 0.000604 |
| mse           | 0.0169   |
| mse_q0        | 0.0572   |
| mse_q1        | 0.00856  |
| mse_q2        | 0.00212  |
| mse_q3        | 0.000597 |
| param_norm    | 347      |
| samples       | 6.68e+04 |
| step          | 260      |
| vb            | 0.00259  |
| vb_q0         | 0.0105   |
| vb_q1         | 6.36e-05 |
| vb_q2         | 1.91e-05 |
| vb_q3         | 7.61e-06 |
----------------------------
----------------------------
| grad_norm     | 34.3     |
| lg_loss_scale | 15.3     |
| loss          | 0.0241   |
| loss_q0       | 0.0829   |
| loss_q1       | 0.00877  |
| loss_q2       | 0.00218  |
| loss_q3       | 0.000644 |
| mse           | 0.0188   |
| mse_q0        | 0.0626   |
| mse_q1        | 0.0087   |
| mse_q2        | 0.00216  |
| mse_q3        | 0.000636 |
| param_norm    | 347      |
| samples       | 6.94e+04 |
| step          | 270      |
| vb            | 0.00523  |
| vb_q0         | 0.0203   |
| vb_q1         | 6.47e-05 |
| vb_q2         | 1.95e-05 |
| vb_q3         | 8.08e-06 |
----------------------------
----------------------------
| grad_norm     | 31.6     |
| lg_loss_scale | 15.3     |
| loss          | 0.0194   |
| loss_q0       | 0.0674   |
| loss_q1       | 0.00888  |
| loss_q2       | 0.0021   |
| loss_q3       | 0.00063  |
| mse           | 0.0175   |
| mse_q0        | 0.0598   |
| mse_q1        | 0.00881  |
| mse_q2        | 0.00208  |
| mse_q3        | 0.000622 |
| param_norm    | 347      |
| samples       | 7.19e+04 |
| step          | 280      |
| vb            | 0.00186  |
| vb_q0         | 0.00757  |
| vb_q1         | 6.54e-05 |
| vb_q2         | 1.88e-05 |
| vb_q3         | 7.89e-06 |
----------------------------
----------------------------
| grad_norm     | 23       |
| lg_loss_scale | 15.3     |
| loss          | 0.0219   |
| loss_q0       | 0.0751   |
| loss_q1       | 0.00871  |
| loss_q2       | 0.00207  |
| loss_q3       | 0.000565 |
| mse           | 0.0177   |
| mse_q0        | 0.0585   |
| mse_q1        | 0.00865  |
| mse_q2        | 0.00205  |
| mse_q3        | 0.000558 |
| param_norm    | 347      |
| samples       | 7.45e+04 |
| step          | 290      |
| vb            | 0.00425  |
| vb_q0         | 0.0167   |
| vb_q1         | 6.43e-05 |
| vb_q2         | 1.86e-05 |
| vb_q3         | 7.07e-06 |
----------------------------
----------------------------
| grad_norm     | 48.9     |
| lg_loss_scale | 15.3     |
| loss          | 0.022    |
| loss_q0       | 0.0761   |
| loss_q1       | 0.00856  |
| loss_q2       | 0.00214  |
| loss_q3       | 0.000649 |
| mse           | 0.0183   |
| mse_q0        | 0.0617   |
| mse_q1        | 0.00849  |
| mse_q2        | 0.00212  |
| mse_q3        | 0.00064  |
| param_norm    | 347      |
| samples       | 7.71e+04 |
| step          | 300      |
| vb            | 0.00363  |
| vb_q0         | 0.0144   |
| vb_q1         | 6.3e-05  |
| vb_q2         | 1.92e-05 |
| vb_q3         | 8.16e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 29.7     |
| lg_loss_scale | 15.3     |
| loss          | 0.0202   |
| loss_q0       | 0.071    |
| loss_q1       | 0.00818  |
| loss_q2       | 0.00206  |
| loss_q3       | 0.000581 |
| mse           | 0.0179   |
| mse_q0        | 0.0618   |
| mse_q1        | 0.00812  |
| mse_q2        | 0.00204  |
| mse_q3        | 0.000574 |
| param_norm    | 347      |
| samples       | 7.96e+04 |
| step          | 310      |
| vb            | 0.00228  |
| vb_q0         | 0.00914  |
| vb_q1         | 6.03e-05 |
| vb_q2         | 1.83e-05 |
| vb_q3         | 7.26e-06 |
----------------------------
----------------------------
| grad_norm     | 24.3     |
| lg_loss_scale | 15.3     |
| loss          | 0.0216   |
| loss_q0       | 0.0788   |
| loss_q1       | 0.00844  |
| loss_q2       | 0.00197  |
| loss_q3       | 0.000532 |
| mse           | 0.0174   |
| mse_q0        | 0.0613   |
| mse_q1        | 0.00838  |
| mse_q2        | 0.00195  |
| mse_q3        | 0.000525 |
| param_norm    | 347      |
| samples       | 8.22e+04 |
| step          | 320      |
| vb            | 0.00422  |
| vb_q0         | 0.0176   |
| vb_q1         | 6.22e-05 |
| vb_q2         | 1.76e-05 |
| vb_q3         | 6.65e-06 |
----------------------------
----------------------------
| grad_norm     | 26.8     |
| lg_loss_scale | 15.3     |
| loss          | 0.0215   |
| loss_q0       | 0.0721   |
| loss_q1       | 0.0084   |
| loss_q2       | 0.00199  |
| loss_q3       | 0.000559 |
| mse           | 0.0198   |
| mse_q0        | 0.0654   |
| mse_q1        | 0.00834  |
| mse_q2        | 0.00197  |
| mse_q3        | 0.000552 |
| param_norm    | 347      |
| samples       | 8.47e+04 |
| step          | 330      |
| vb            | 0.00176  |
| vb_q0         | 0.00671  |
| vb_q1         | 6.19e-05 |
| vb_q2         | 1.79e-05 |
| vb_q3         | 7e-06    |
----------------------------
----------------------------
| grad_norm     | 17.2     |
| lg_loss_scale | 15.3     |
| loss          | 0.0201   |
| loss_q0       | 0.0726   |
| loss_q1       | 0.00863  |
| loss_q2       | 0.00191  |
| loss_q3       | 0.000488 |
| mse           | 0.0166   |
| mse_q0        | 0.058    |
| mse_q1        | 0.00856  |
| mse_q2        | 0.00189  |
| mse_q3        | 0.000482 |
| param_norm    | 347      |
| samples       | 8.73e+04 |
| step          | 340      |
| vb            | 0.00351  |
| vb_q0         | 0.0147   |
| vb_q1         | 6.37e-05 |
| vb_q2         | 1.71e-05 |
| vb_q3         | 6.14e-06 |
----------------------------
----------------------------
| grad_norm     | 26.2     |
| lg_loss_scale | 15.3     |
| loss          | 0.0194   |
| loss_q0       | 0.0678   |
| loss_q1       | 0.00827  |
| loss_q2       | 0.00192  |
| loss_q3       | 0.000496 |
| mse           | 0.0173   |
| mse_q0        | 0.0594   |
| mse_q1        | 0.00821  |
| mse_q2        | 0.0019   |
| mse_q3        | 0.000489 |
| param_norm    | 347      |
| samples       | 8.99e+04 |
| step          | 350      |
| vb            | 0.0021   |
| vb_q0         | 0.00844  |
| vb_q1         | 6.09e-05 |
| vb_q2         | 1.71e-05 |
| vb_q3         | 6.19e-06 |
----------------------------
----------------------------
| grad_norm     | 31.6     |
| lg_loss_scale | 15.4     |
| loss          | 0.0192   |
| loss_q0       | 0.0673   |
| loss_q1       | 0.00818  |
| loss_q2       | 0.00199  |
| loss_q3       | 0.000498 |
| mse           | 0.0169   |
| mse_q0        | 0.0579   |
| mse_q1        | 0.00812  |
| mse_q2        | 0.00197  |
| mse_q3        | 0.000492 |
| param_norm    | 347      |
| samples       | 9.24e+04 |
| step          | 360      |
| vb            | 0.00236  |
| vb_q0         | 0.00947  |
| vb_q1         | 6.03e-05 |
| vb_q2         | 1.77e-05 |
| vb_q3         | 6.25e-06 |
----------------------------
----------------------------
| grad_norm     | 35.6     |
| lg_loss_scale | 15.4     |
| loss          | 0.0195   |
| loss_q0       | 0.065    |
| loss_q1       | 0.00804  |
| loss_q2       | 0.00201  |
| loss_q3       | 0.000502 |
| mse           | 0.0178   |
| mse_q0        | 0.0583   |
| mse_q1        | 0.00799  |
| mse_q2        | 0.00199  |
| mse_q3        | 0.000496 |
| param_norm    | 347      |
| samples       | 9.5e+04  |
| step          | 370      |
| vb            | 0.00175  |
| vb_q0         | 0.00669  |
| vb_q1         | 5.94e-05 |
| vb_q2         | 1.78e-05 |
| vb_q3         | 6.27e-06 |
----------------------------
----------------------------
| grad_norm     | 18       |
| lg_loss_scale | 15.4     |
| loss          | 0.0186   |
| loss_q0       | 0.0659   |
| loss_q1       | 0.00829  |
| loss_q2       | 0.00192  |
| loss_q3       | 0.000447 |
| mse           | 0.0161   |
| mse_q0        | 0.0554   |
| mse_q1        | 0.00823  |
| mse_q2        | 0.0019   |
| mse_q3        | 0.000442 |
| param_norm    | 347      |
| samples       | 9.75e+04 |
| step          | 380      |
| vb            | 0.00255  |
| vb_q0         | 0.0105   |
| vb_q1         | 6.12e-05 |
| vb_q2         | 1.7e-05  |
| vb_q3         | 5.59e-06 |
----------------------------
----------------------------
| grad_norm     | 22.6     |
| lg_loss_scale | 15.4     |
| loss          | 0.0183   |
| loss_q0       | 0.0613   |
| loss_q1       | 0.0084   |
| loss_q2       | 0.00191  |
| loss_q3       | 0.000456 |
| mse           | 0.0164   |
| mse_q0        | 0.0539   |
| mse_q1        | 0.00834  |
| mse_q2        | 0.0019   |
| mse_q3        | 0.00045  |
| param_norm    | 347      |
| samples       | 1e+05    |
| step          | 390      |
| vb            | 0.0019   |
| vb_q0         | 0.00741  |
| vb_q1         | 6.18e-05 |
| vb_q2         | 1.7e-05  |
| vb_q3         | 5.68e-06 |
----------------------------
----------------------------
| grad_norm     | 44.2     |
| lg_loss_scale | 15.4     |
| loss          | 0.0209   |
| loss_q0       | 0.0701   |
| loss_q1       | 0.00791  |
| loss_q2       | 0.00197  |
| loss_q3       | 0.000507 |
| mse           | 0.0177   |
| mse_q0        | 0.0576   |
| mse_q1        | 0.00785  |
| mse_q2        | 0.00195  |
| mse_q3        | 0.000501 |
| param_norm    | 347      |
| samples       | 1.03e+05 |
| step          | 400      |
| vb            | 0.00328  |
| vb_q0         | 0.0124   |
| vb_q1         | 5.81e-05 |
| vb_q2         | 1.75e-05 |
| vb_q3         | 6.38e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 38.3     |
| lg_loss_scale | 15.4     |
| loss          | 0.0204   |
| loss_q0       | 0.0698   |
| loss_q1       | 0.00819  |
| loss_q2       | 0.00195  |
| loss_q3       | 0.000512 |
| mse           | 0.0189   |
| mse_q0        | 0.064    |
| mse_q1        | 0.00813  |
| mse_q2        | 0.00193  |
| mse_q3        | 0.000506 |
| param_norm    | 347      |
| samples       | 1.05e+05 |
| step          | 410      |
| vb            | 0.0015   |
| vb_q0         | 0.0058   |
| vb_q1         | 6.03e-05 |
| vb_q2         | 1.73e-05 |
| vb_q3         | 6.39e-06 |
----------------------------
----------------------------
| grad_norm     | 23.6     |
| lg_loss_scale | 15.4     |
| loss          | 0.0181   |
| loss_q0       | 0.0628   |
| loss_q1       | 0.00825  |
| loss_q2       | 0.00184  |
| loss_q3       | 0.000456 |
| mse           | 0.016    |
| mse_q0        | 0.0544   |
| mse_q1        | 0.00819  |
| mse_q2        | 0.00183  |
| mse_q3        | 0.00045  |
| param_norm    | 347      |
| samples       | 1.08e+05 |
| step          | 420      |
| vb            | 0.00209  |
| vb_q0         | 0.0084   |
| vb_q1         | 6.07e-05 |
| vb_q2         | 1.65e-05 |
| vb_q3         | 5.69e-06 |
----------------------------
----------------------------
| grad_norm     | 23.1     |
| lg_loss_scale | 15.4     |
| loss          | 0.023    |
| loss_q0       | 0.0823   |
| loss_q1       | 0.00795  |
| loss_q2       | 0.00188  |
| loss_q3       | 0.00044  |
| mse           | 0.0177   |
| mse_q0        | 0.0614   |
| mse_q1        | 0.00789  |
| mse_q2        | 0.00186  |
| mse_q3        | 0.000435 |
| param_norm    | 347      |
| samples       | 1.1e+05  |
| step          | 430      |
| vb            | 0.00521  |
| vb_q0         | 0.0209   |
| vb_q1         | 5.86e-05 |
| vb_q2         | 1.67e-05 |
| vb_q3         | 5.44e-06 |
----------------------------
----------------------------
| grad_norm     | 17.3     |
| lg_loss_scale | 15.4     |
| loss          | 0.0216   |
| loss_q0       | 0.0796   |
| loss_q1       | 0.00773  |
| loss_q2       | 0.00182  |
| loss_q3       | 0.000435 |
| mse           | 0.0167   |
| mse_q0        | 0.0593   |
| mse_q1        | 0.00767  |
| mse_q2        | 0.0018   |
| mse_q3        | 0.00043  |
| param_norm    | 347      |
| samples       | 1.13e+05 |
| step          | 440      |
| vb            | 0.00488  |
| vb_q0         | 0.0203   |
| vb_q1         | 5.69e-05 |
| vb_q2         | 1.63e-05 |
| vb_q3         | 5.39e-06 |
----------------------------
----------------------------
| grad_norm     | 35.1     |
| lg_loss_scale | 15.4     |
| loss          | 0.0226   |
| loss_q0       | 0.0819   |
| loss_q1       | 0.00816  |
| loss_q2       | 0.00181  |
| loss_q3       | 0.000464 |
| mse           | 0.0178   |
| mse_q0        | 0.0623   |
| mse_q1        | 0.0081   |
| mse_q2        | 0.00179  |
| mse_q3        | 0.000459 |
| param_norm    | 347      |
| samples       | 1.15e+05 |
| step          | 450      |
| vb            | 0.00478  |
| vb_q0         | 0.0195   |
| vb_q1         | 6.01e-05 |
| vb_q2         | 1.62e-05 |
| vb_q3         | 5.77e-06 |
----------------------------
----------------------------
| grad_norm     | 40.1     |
| lg_loss_scale | 15.5     |
| loss          | 0.0206   |
| loss_q0       | 0.0708   |
| loss_q1       | 0.00814  |
| loss_q2       | 0.0019   |
| loss_q3       | 0.000481 |
| mse           | 0.0176   |
| mse_q0        | 0.0593   |
| mse_q1        | 0.00808  |
| mse_q2        | 0.00188  |
| mse_q3        | 0.000475 |
| param_norm    | 347      |
| samples       | 1.18e+05 |
| step          | 460      |
| vb            | 0.00294  |
| vb_q0         | 0.0115   |
| vb_q1         | 6.01e-05 |
| vb_q2         | 1.69e-05 |
| vb_q3         | 6.03e-06 |
----------------------------
----------------------------
| grad_norm     | 21.3     |
| lg_loss_scale | 15.5     |
| loss          | 0.0215   |
| loss_q0       | 0.0756   |
| loss_q1       | 0.00805  |
| loss_q2       | 0.00186  |
| loss_q3       | 0.000466 |
| mse           | 0.0167   |
| mse_q0        | 0.0568   |
| mse_q1        | 0.00799  |
| mse_q2        | 0.00184  |
| mse_q3        | 0.00046  |
| param_norm    | 347      |
| samples       | 1.21e+05 |
| step          | 470      |
| vb            | 0.00473  |
| vb_q0         | 0.0188   |
| vb_q1         | 5.93e-05 |
| vb_q2         | 1.66e-05 |
| vb_q3         | 5.78e-06 |
----------------------------
----------------------------
| grad_norm     | 17.9     |
| lg_loss_scale | 15.5     |
| loss          | 0.0219   |
| loss_q0       | 0.0773   |
| loss_q1       | 0.00785  |
| loss_q2       | 0.0018   |
| loss_q3       | 0.00041  |
| mse           | 0.017    |
| mse_q0        | 0.0578   |
| mse_q1        | 0.00779  |
| mse_q2        | 0.00178  |
| mse_q3        | 0.000405 |
| param_norm    | 347      |
| samples       | 1.23e+05 |
| step          | 480      |
| vb            | 0.00494  |
| vb_q0         | 0.0196   |
| vb_q1         | 5.78e-05 |
| vb_q2         | 1.6e-05  |
| vb_q3         | 5.1e-06  |
----------------------------
----------------------------
| grad_norm     | 18.8     |
| lg_loss_scale | 15.5     |
| loss          | 0.0178   |
| loss_q0       | 0.0589   |
| loss_q1       | 0.00814  |
| loss_q2       | 0.00178  |
| loss_q3       | 0.000403 |
| mse           | 0.016    |
| mse_q0        | 0.0521   |
| mse_q1        | 0.00808  |
| mse_q2        | 0.00176  |
| mse_q3        | 0.000398 |
| param_norm    | 347      |
| samples       | 1.26e+05 |
| step          | 490      |
| vb            | 0.00178  |
| vb_q0         | 0.00683  |
| vb_q1         | 5.99e-05 |
| vb_q2         | 1.58e-05 |
| vb_q3         | 5e-06    |
----------------------------
----------------------------
| grad_norm     | 29.1     |
| lg_loss_scale | 15.5     |
| loss          | 0.0196   |
| loss_q0       | 0.0662   |
| loss_q1       | 0.00818  |
| loss_q2       | 0.00177  |
| loss_q3       | 0.00041  |
| mse           | 0.0168   |
| mse_q0        | 0.0554   |
| mse_q1        | 0.00812  |
| mse_q2        | 0.00175  |
| mse_q3        | 0.000405 |
| param_norm    | 347      |
| samples       | 1.28e+05 |
| step          | 500      |
| vb            | 0.00279  |
| vb_q0         | 0.0107   |
| vb_q1         | 6.03e-05 |
| vb_q2         | 1.57e-05 |
| vb_q3         | 5.13e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 31.5     |
| lg_loss_scale | 15.5     |
| loss          | 0.0229   |
| loss_q0       | 0.0818   |
| loss_q1       | 0.00827  |
| loss_q2       | 0.00182  |
| loss_q3       | 0.000425 |
| mse           | 0.0178   |
| mse_q0        | 0.0613   |
| mse_q1        | 0.00821  |
| mse_q2        | 0.00181  |
| mse_q3        | 0.000419 |
| param_norm    | 347      |
| samples       | 1.31e+05 |
| step          | 510      |
| vb            | 0.00511  |
| vb_q0         | 0.0205   |
| vb_q1         | 6.1e-05  |
| vb_q2         | 1.63e-05 |
| vb_q3         | 5.31e-06 |
----------------------------
----------------------------
| grad_norm     | 30.6     |
| lg_loss_scale | 15.5     |
| loss          | 0.0179   |
| loss_q0       | 0.0621   |
| loss_q1       | 0.0081   |
| loss_q2       | 0.00179  |
| loss_q3       | 0.000414 |
| mse           | 0.0163   |
| mse_q0        | 0.0558   |
| mse_q1        | 0.00804  |
| mse_q2        | 0.00177  |
| mse_q3        | 0.000409 |
| param_norm    | 347      |
| samples       | 1.33e+05 |
| step          | 520      |
| vb            | 0.00157  |
| vb_q0         | 0.00625  |
| vb_q1         | 5.95e-05 |
| vb_q2         | 1.59e-05 |
| vb_q3         | 5.19e-06 |
----------------------------
----------------------------
| grad_norm     | 27.1     |
| lg_loss_scale | 15.5     |
| loss          | 0.019    |
| loss_q0       | 0.0629   |
| loss_q1       | 0.00806  |
| loss_q2       | 0.00182  |
| loss_q3       | 0.000402 |
| mse           | 0.0171   |
| mse_q0        | 0.0556   |
| mse_q1        | 0.008    |
| mse_q2        | 0.00181  |
| mse_q3        | 0.000397 |
| param_norm    | 347      |
| samples       | 1.36e+05 |
| step          | 530      |
| vb            | 0.00194  |
| vb_q0         | 0.0073   |
| vb_q1         | 5.92e-05 |
| vb_q2         | 1.62e-05 |
| vb_q3         | 5e-06    |
----------------------------
----------------------------
| grad_norm     | 22.2     |
| lg_loss_scale | 15.5     |
| loss          | 0.0176   |
| loss_q0       | 0.0594   |
| loss_q1       | 0.00763  |
| loss_q2       | 0.00179  |
| loss_q3       | 0.000381 |
| mse           | 0.0165   |
| mse_q0        | 0.0552   |
| mse_q1        | 0.00757  |
| mse_q2        | 0.00177  |
| mse_q3        | 0.000377 |
| param_norm    | 347      |
| samples       | 1.38e+05 |
| step          | 540      |
| vb            | 0.0011   |
| vb_q0         | 0.00422  |
| vb_q1         | 5.62e-05 |
| vb_q2         | 1.59e-05 |
| vb_q3         | 4.75e-06 |
----------------------------
----------------------------
| grad_norm     | 18.8     |
| lg_loss_scale | 15.5     |
| loss          | 0.017    |
| loss_q0       | 0.0582   |
| loss_q1       | 0.00818  |
| loss_q2       | 0.00176  |
| loss_q3       | 0.000375 |
| mse           | 0.0158   |
| mse_q0        | 0.0536   |
| mse_q1        | 0.00812  |
| mse_q2        | 0.00174  |
| mse_q3        | 0.00037  |
| param_norm    | 347      |
| samples       | 1.41e+05 |
| step          | 550      |
| vb            | 0.00117  |
| vb_q0         | 0.00463  |
| vb_q1         | 6.03e-05 |
| vb_q2         | 1.56e-05 |
| vb_q3         | 4.66e-06 |
----------------------------
----------------------------
| grad_norm     | 15.3     |
| lg_loss_scale | 15.6     |
| loss          | 0.0204   |
| loss_q0       | 0.0676   |
| loss_q1       | 0.00801  |
| loss_q2       | 0.00178  |
| loss_q3       | 0.000367 |
| mse           | 0.0182   |
| mse_q0        | 0.0593   |
| mse_q1        | 0.00795  |
| mse_q2        | 0.00177  |
| mse_q3        | 0.000363 |
| param_norm    | 347      |
| samples       | 1.44e+05 |
| step          | 560      |
| vb            | 0.00218  |
| vb_q0         | 0.00821  |
| vb_q1         | 5.88e-05 |
| vb_q2         | 1.58e-05 |
| vb_q3         | 4.54e-06 |
----------------------------
----------------------------
| grad_norm     | 22.3     |
| lg_loss_scale | 15.6     |
| loss          | 0.0182   |
| loss_q0       | 0.0669   |
| loss_q1       | 0.00767  |
| loss_q2       | 0.00178  |
| loss_q3       | 0.00037  |
| mse           | 0.0159   |
| mse_q0        | 0.057    |
| mse_q1        | 0.00761  |
| mse_q2        | 0.00177  |
| mse_q3        | 0.000366 |
| param_norm    | 347      |
| samples       | 1.46e+05 |
| step          | 570      |
| vb            | 0.00233  |
| vb_q0         | 0.00986  |
| vb_q1         | 5.64e-05 |
| vb_q2         | 1.58e-05 |
| vb_q3         | 4.61e-06 |
----------------------------
----------------------------
| grad_norm     | 27.6     |
| lg_loss_scale | 15.6     |
| loss          | 0.0205   |
| loss_q0       | 0.0713   |
| loss_q1       | 0.00783  |
| loss_q2       | 0.00176  |
| loss_q3       | 0.000388 |
| mse           | 0.0172   |
| mse_q0        | 0.0582   |
| mse_q1        | 0.00777  |
| mse_q2        | 0.00175  |
| mse_q3        | 0.000384 |
| param_norm    | 347      |
| samples       | 1.49e+05 |
| step          | 580      |
| vb            | 0.00331  |
| vb_q0         | 0.0131   |
| vb_q1         | 5.75e-05 |
| vb_q2         | 1.57e-05 |
| vb_q3         | 4.83e-06 |
----------------------------
----------------------------
| grad_norm     | 28.7     |
| lg_loss_scale | 15.6     |
| loss          | 0.0187   |
| loss_q0       | 0.0659   |
| loss_q1       | 0.00795  |
| loss_q2       | 0.00174  |
| loss_q3       | 0.000399 |
| mse           | 0.015    |
| mse_q0        | 0.0508   |
| mse_q1        | 0.00789  |
| mse_q2        | 0.00172  |
| mse_q3        | 0.000394 |
| param_norm    | 347      |
| samples       | 1.51e+05 |
| step          | 590      |
| vb            | 0.00373  |
| vb_q0         | 0.0151   |
| vb_q1         | 5.86e-05 |
| vb_q2         | 1.55e-05 |
| vb_q3         | 4.96e-06 |
----------------------------
----------------------------
| grad_norm     | 27.9     |
| lg_loss_scale | 15.6     |
| loss          | 0.0198   |
| loss_q0       | 0.0702   |
| loss_q1       | 0.00791  |
| loss_q2       | 0.00181  |
| loss_q3       | 0.000403 |
| mse           | 0.0169   |
| mse_q0        | 0.0584   |
| mse_q1        | 0.00785  |
| mse_q2        | 0.0018   |
| mse_q3        | 0.000398 |
| param_norm    | 347      |
| samples       | 1.54e+05 |
| step          | 600      |
| vb            | 0.00292  |
| vb_q0         | 0.0118   |
| vb_q1         | 5.83e-05 |
| vb_q2         | 1.61e-05 |
| vb_q3         | 5.03e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 24.8     |
| lg_loss_scale | 15.6     |
| loss          | 0.0203   |
| loss_q0       | 0.07     |
| loss_q1       | 0.0077   |
| loss_q2       | 0.0017   |
| loss_q3       | 0.000377 |
| mse           | 0.0178   |
| mse_q0        | 0.0603   |
| mse_q1        | 0.00765  |
| mse_q2        | 0.00168  |
| mse_q3        | 0.000373 |
| param_norm    | 347      |
| samples       | 1.56e+05 |
| step          | 610      |
| vb            | 0.0025   |
| vb_q0         | 0.00969  |
| vb_q1         | 5.67e-05 |
| vb_q2         | 1.51e-05 |
| vb_q3         | 4.69e-06 |
----------------------------
----------------------------
| grad_norm     | 26.6     |
| lg_loss_scale | 15.6     |
| loss          | 0.0224   |
| loss_q0       | 0.084    |
| loss_q1       | 0.00788  |
| loss_q2       | 0.00172  |
| loss_q3       | 0.000386 |
| mse           | 0.0173   |
| mse_q0        | 0.0625   |
| mse_q1        | 0.00782  |
| mse_q2        | 0.00171  |
| mse_q3        | 0.000381 |
| param_norm    | 347      |
| samples       | 1.59e+05 |
| step          | 620      |
| vb            | 0.0051   |
| vb_q0         | 0.0215   |
| vb_q1         | 5.82e-05 |
| vb_q2         | 1.54e-05 |
| vb_q3         | 4.79e-06 |
----------------------------
----------------------------
| grad_norm     | 22.4     |
| lg_loss_scale | 15.6     |
| loss          | 0.0203   |
| loss_q0       | 0.0703   |
| loss_q1       | 0.00782  |
| loss_q2       | 0.00185  |
| loss_q3       | 0.000385 |
| mse           | 0.0166   |
| mse_q0        | 0.0556   |
| mse_q1        | 0.00777  |
| mse_q2        | 0.00183  |
| mse_q3        | 0.00038  |
| param_norm    | 347      |
| samples       | 1.62e+05 |
| step          | 630      |
| vb            | 0.00374  |
| vb_q0         | 0.0147   |
| vb_q1         | 5.76e-05 |
| vb_q2         | 1.64e-05 |
| vb_q3         | 4.75e-06 |
----------------------------
----------------------------
| grad_norm     | 16.8     |
| lg_loss_scale | 15.6     |
| loss          | 0.0198   |
| loss_q0       | 0.0674   |
| loss_q1       | 0.00774  |
| loss_q2       | 0.00165  |
| loss_q3       | 0.000371 |
| mse           | 0.0164   |
| mse_q0        | 0.0541   |
| mse_q1        | 0.00768  |
| mse_q2        | 0.00164  |
| mse_q3        | 0.000366 |
| param_norm    | 347      |
| samples       | 1.64e+05 |
| step          | 640      |
| vb            | 0.00344  |
| vb_q0         | 0.0133   |
| vb_q1         | 5.69e-05 |
| vb_q2         | 1.48e-05 |
| vb_q3         | 4.63e-06 |
----------------------------
----------------------------
| grad_norm     | 13.9     |
| lg_loss_scale | 15.6     |
| loss          | 0.0195   |
| loss_q0       | 0.0728   |
| loss_q1       | 0.00774  |
| loss_q2       | 0.0017   |
| loss_q3       | 0.000353 |
| mse           | 0.016    |
| mse_q0        | 0.058    |
| mse_q1        | 0.00768  |
| mse_q2        | 0.00168  |
| mse_q3        | 0.000348 |
| param_norm    | 347      |
| samples       | 1.67e+05 |
| step          | 650      |
| vb            | 0.00349  |
| vb_q0         | 0.0148   |
| vb_q1         | 5.7e-05  |
| vb_q2         | 1.51e-05 |
| vb_q3         | 4.36e-06 |
----------------------------
----------------------------
| grad_norm     | 19.9     |
| lg_loss_scale | 15.7     |
| loss          | 0.019    |
| loss_q0       | 0.069    |
| loss_q1       | 0.00761  |
| loss_q2       | 0.00173  |
| loss_q3       | 0.000344 |
| mse           | 0.0162   |
| mse_q0        | 0.0573   |
| mse_q1        | 0.00756  |
| mse_q2        | 0.00171  |
| mse_q3        | 0.00034  |
| param_norm    | 347      |
| samples       | 1.69e+05 |
| step          | 660      |
| vb            | 0.00282  |
| vb_q0         | 0.0117   |
| vb_q1         | 5.6e-05  |
| vb_q2         | 1.53e-05 |
| vb_q3         | 4.27e-06 |
----------------------------
----------------------------
| grad_norm     | 22.6     |
| lg_loss_scale | 15.7     |
| loss          | 0.0197   |
| loss_q0       | 0.0721   |
| loss_q1       | 0.00764  |
| loss_q2       | 0.00179  |
| loss_q3       | 0.000365 |
| mse           | 0.0163   |
| mse_q0        | 0.0578   |
| mse_q1        | 0.00758  |
| mse_q2        | 0.00177  |
| mse_q3        | 0.000361 |
| param_norm    | 347      |
| samples       | 1.72e+05 |
| step          | 670      |
| vb            | 0.00343  |
| vb_q0         | 0.0143   |
| vb_q1         | 5.63e-05 |
| vb_q2         | 1.58e-05 |
| vb_q3         | 4.52e-06 |
----------------------------
----------------------------
| grad_norm     | 26.4     |
| lg_loss_scale | 15.7     |
| loss          | 0.0194   |
| loss_q0       | 0.0661   |
| loss_q1       | 0.00757  |
| loss_q2       | 0.00181  |
| loss_q3       | 0.000371 |
| mse           | 0.0165   |
| mse_q0        | 0.0551   |
| mse_q1        | 0.00751  |
| mse_q2        | 0.0018   |
| mse_q3        | 0.000366 |
| param_norm    | 347      |
| samples       | 1.74e+05 |
| step          | 680      |
| vb            | 0.00284  |
| vb_q0         | 0.011    |
| vb_q1         | 5.57e-05 |
| vb_q2         | 1.6e-05  |
| vb_q3         | 4.57e-06 |
----------------------------
----------------------------
| grad_norm     | 24.9     |
| lg_loss_scale | 15.7     |
| loss          | 0.0207   |
| loss_q0       | 0.072    |
| loss_q1       | 0.00756  |
| loss_q2       | 0.0018   |
| loss_q3       | 0.00037  |
| mse           | 0.0164   |
| mse_q0        | 0.055    |
| mse_q1        | 0.00751  |
| mse_q2        | 0.00178  |
| mse_q3        | 0.000365 |
| param_norm    | 347      |
| samples       | 1.77e+05 |
| step          | 690      |
| vb            | 0.00433  |
| vb_q0         | 0.017    |
| vb_q1         | 5.58e-05 |
| vb_q2         | 1.59e-05 |
| vb_q3         | 4.64e-06 |
----------------------------
----------------------------
| grad_norm     | 20.4     |
| lg_loss_scale | 15.7     |
| loss          | 0.0211   |
| loss_q0       | 0.0734   |
| loss_q1       | 0.0078   |
| loss_q2       | 0.00181  |
| loss_q3       | 0.000388 |
| mse           | 0.0164   |
| mse_q0        | 0.0548   |
| mse_q1        | 0.00774  |
| mse_q2        | 0.00179  |
| mse_q3        | 0.000383 |
| param_norm    | 347      |
| samples       | 1.79e+05 |
| step          | 700      |
| vb            | 0.00473  |
| vb_q0         | 0.0186   |
| vb_q1         | 5.73e-05 |
| vb_q2         | 1.61e-05 |
| vb_q3         | 4.81e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 17.8     |
| lg_loss_scale | 15.7     |
| loss          | 0.0183   |
| loss_q0       | 0.0633   |
| loss_q1       | 0.00764  |
| loss_q2       | 0.00174  |
| loss_q3       | 0.000348 |
| mse           | 0.0163   |
| mse_q0        | 0.0554   |
| mse_q1        | 0.00758  |
| mse_q2        | 0.00172  |
| mse_q3        | 0.000344 |
| param_norm    | 347      |
| samples       | 1.82e+05 |
| step          | 710      |
| vb            | 0.00199  |
| vb_q0         | 0.0079   |
| vb_q1         | 5.62e-05 |
| vb_q2         | 1.54e-05 |
| vb_q3         | 4.31e-06 |
----------------------------
----------------------------
| grad_norm     | 28.3     |
| lg_loss_scale | 15.7     |
| loss          | 0.0183   |
| loss_q0       | 0.0623   |
| loss_q1       | 0.00778  |
| loss_q2       | 0.00168  |
| loss_q3       | 0.000376 |
| mse           | 0.0163   |
| mse_q0        | 0.0545   |
| mse_q1        | 0.00772  |
| mse_q2        | 0.00166  |
| mse_q3        | 0.000371 |
| param_norm    | 347      |
| samples       | 1.85e+05 |
| step          | 720      |
| vb            | 0.00199  |
| vb_q0         | 0.00774  |
| vb_q1         | 5.72e-05 |
| vb_q2         | 1.49e-05 |
| vb_q3         | 4.65e-06 |
----------------------------
----------------------------
| grad_norm     | 22.9     |
| lg_loss_scale | 15.7     |
| loss          | 0.0197   |
| loss_q0       | 0.065    |
| loss_q1       | 0.00723  |
| loss_q2       | 0.00173  |
| loss_q3       | 0.000349 |
| mse           | 0.017    |
| mse_q0        | 0.0549   |
| mse_q1        | 0.00718  |
| mse_q2        | 0.00171  |
| mse_q3        | 0.000344 |
| param_norm    | 347      |
| samples       | 1.87e+05 |
| step          | 730      |
| vb            | 0.00271  |
| vb_q0         | 0.0101   |
| vb_q1         | 5.31e-05 |
| vb_q2         | 1.54e-05 |
| vb_q3         | 4.36e-06 |
----------------------------
----------------------------
| grad_norm     | 24.2     |
| lg_loss_scale | 15.7     |
| loss          | 0.021    |
| loss_q0       | 0.0736   |
| loss_q1       | 0.0076   |
| loss_q2       | 0.0017   |
| loss_q3       | 0.000355 |
| mse           | 0.0174   |
| mse_q0        | 0.0593   |
| mse_q1        | 0.00754  |
| mse_q2        | 0.00169  |
| mse_q3        | 0.00035  |
| param_norm    | 347      |
| samples       | 1.9e+05  |
| step          | 740      |
| vb            | 0.00364  |
| vb_q0         | 0.0143   |
| vb_q1         | 5.58e-05 |
| vb_q2         | 1.52e-05 |
| vb_q3         | 4.41e-06 |
----------------------------
----------------------------
| grad_norm     | 17.9     |
| lg_loss_scale | 15.7     |
| loss          | 0.0176   |
| loss_q0       | 0.0597   |
| loss_q1       | 0.00776  |
| loss_q2       | 0.00172  |
| loss_q3       | 0.000337 |
| mse           | 0.0154   |
| mse_q0        | 0.0508   |
| mse_q1        | 0.00771  |
| mse_q2        | 0.0017   |
| mse_q3        | 0.000333 |
| param_norm    | 347      |
| samples       | 1.92e+05 |
| step          | 750      |
| vb            | 0.00227  |
| vb_q0         | 0.00888  |
| vb_q1         | 5.69e-05 |
| vb_q2         | 1.52e-05 |
| vb_q3         | 4.17e-06 |
----------------------------
----------------------------
| grad_norm     | 18.2     |
| lg_loss_scale | 15.8     |
| loss          | 0.0179   |
| loss_q0       | 0.0638   |
| loss_q1       | 0.00767  |
| loss_q2       | 0.00165  |
| loss_q3       | 0.000323 |
| mse           | 0.0153   |
| mse_q0        | 0.053    |
| mse_q1        | 0.00762  |
| mse_q2        | 0.00164  |
| mse_q3        | 0.000319 |
| param_norm    | 347      |
| samples       | 1.95e+05 |
| step          | 760      |
| vb            | 0.00263  |
| vb_q0         | 0.0108   |
| vb_q1         | 5.65e-05 |
| vb_q2         | 1.46e-05 |
| vb_q3         | 4.03e-06 |
----------------------------
----------------------------
| grad_norm     | 31.8     |
| lg_loss_scale | 15.8     |
| loss          | 0.019    |
| loss_q0       | 0.064    |
| loss_q1       | 0.00745  |
| loss_q2       | 0.00176  |
| loss_q3       | 0.000391 |
| mse           | 0.017    |
| mse_q0        | 0.0567   |
| mse_q1        | 0.0074   |
| mse_q2        | 0.00175  |
| mse_q3        | 0.000386 |
| param_norm    | 347      |
| samples       | 1.97e+05 |
| step          | 770      |
| vb            | 0.00191  |
| vb_q0         | 0.0073   |
| vb_q1         | 5.49e-05 |
| vb_q2         | 1.57e-05 |
| vb_q3         | 4.87e-06 |
----------------------------
----------------------------
| grad_norm     | 25       |
| lg_loss_scale | 15.8     |
| loss          | 0.0197   |
| loss_q0       | 0.0649   |
| loss_q1       | 0.00761  |
| loss_q2       | 0.00165  |
| loss_q3       | 0.000351 |
| mse           | 0.0169   |
| mse_q0        | 0.0546   |
| mse_q1        | 0.00756  |
| mse_q2        | 0.00164  |
| mse_q3        | 0.000347 |
| param_norm    | 347      |
| samples       | 2e+05    |
| step          | 780      |
| vb            | 0.00278  |
| vb_q0         | 0.0103   |
| vb_q1         | 5.61e-05 |
| vb_q2         | 1.47e-05 |
| vb_q3         | 4.35e-06 |
----------------------------
----------------------------
| grad_norm     | 16.7     |
| lg_loss_scale | 15.8     |
| loss          | 0.0186   |
| loss_q0       | 0.0644   |
| loss_q1       | 0.00762  |
| loss_q2       | 0.00167  |
| loss_q3       | 0.000319 |
| mse           | 0.0162   |
| mse_q0        | 0.0551   |
| mse_q1        | 0.00756  |
| mse_q2        | 0.00165  |
| mse_q3        | 0.000315 |
| param_norm    | 347      |
| samples       | 2.02e+05 |
| step          | 790      |
| vb            | 0.00234  |
| vb_q0         | 0.00928  |
| vb_q1         | 5.61e-05 |
| vb_q2         | 1.48e-05 |
| vb_q3         | 3.95e-06 |
----------------------------
----------------------------
| grad_norm     | 15.3     |
| lg_loss_scale | 15.8     |
| loss          | 0.0199   |
| loss_q0       | 0.0682   |
| loss_q1       | 0.00734  |
| loss_q2       | 0.0017   |
| loss_q3       | 0.000335 |
| mse           | 0.0166   |
| mse_q0        | 0.0553   |
| mse_q1        | 0.00728  |
| mse_q2        | 0.00169  |
| mse_q3        | 0.000331 |
| param_norm    | 347      |
| samples       | 2.05e+05 |
| step          | 800      |
| vb            | 0.00333  |
| vb_q0         | 0.0129   |
| vb_q1         | 5.4e-05  |
| vb_q2         | 1.5e-05  |
| vb_q3         | 4.12e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 20.3     |
| lg_loss_scale | 15.8     |
| loss          | 0.0218   |
| loss_q0       | 0.0768   |
| loss_q1       | 0.00748  |
| loss_q2       | 0.00165  |
| loss_q3       | 0.000349 |
| mse           | 0.0177   |
| mse_q0        | 0.0605   |
| mse_q1        | 0.00742  |
| mse_q2        | 0.00163  |
| mse_q3        | 0.000345 |
| param_norm    | 347      |
| samples       | 2.08e+05 |
| step          | 810      |
| vb            | 0.00413  |
| vb_q0         | 0.0163   |
| vb_q1         | 5.5e-05  |
| vb_q2         | 1.47e-05 |
| vb_q3         | 4.32e-06 |
----------------------------
----------------------------
| grad_norm     | 24.2     |
| lg_loss_scale | 15.8     |
| loss          | 0.0187   |
| loss_q0       | 0.0629   |
| loss_q1       | 0.00744  |
| loss_q2       | 0.00167  |
| loss_q3       | 0.000351 |
| mse           | 0.0166   |
| mse_q0        | 0.055    |
| mse_q1        | 0.00738  |
| mse_q2        | 0.00166  |
| mse_q3        | 0.000347 |
| param_norm    | 347      |
| samples       | 2.1e+05  |
| step          | 820      |
| vb            | 0.00206  |
| vb_q0         | 0.00781  |
| vb_q1         | 5.47e-05 |
| vb_q2         | 1.49e-05 |
| vb_q3         | 4.34e-06 |
----------------------------
----------------------------
| grad_norm     | 18.7     |
| lg_loss_scale | 15.8     |
| loss          | 0.0164   |
| loss_q0       | 0.0555   |
| loss_q1       | 0.00752  |
| loss_q2       | 0.00165  |
| loss_q3       | 0.000321 |
| mse           | 0.0153   |
| mse_q0        | 0.0513   |
| mse_q1        | 0.00747  |
| mse_q2        | 0.00164  |
| mse_q3        | 0.000317 |
| param_norm    | 347      |
| samples       | 2.13e+05 |
| step          | 830      |
| vb            | 0.00109  |
| vb_q0         | 0.00422  |
| vb_q1         | 5.53e-05 |
| vb_q2         | 1.47e-05 |
| vb_q3         | 3.96e-06 |
----------------------------
----------------------------
| grad_norm     | 19.8     |
| lg_loss_scale | 15.8     |
| loss          | 0.017    |
| loss_q0       | 0.0607   |
| loss_q1       | 0.00743  |
| loss_q2       | 0.00164  |
| loss_q3       | 0.00032  |
| mse           | 0.0156   |
| mse_q0        | 0.0549   |
| mse_q1        | 0.00737  |
| mse_q2        | 0.00163  |
| mse_q3        | 0.000316 |
| param_norm    | 347      |
| samples       | 2.15e+05 |
| step          | 840      |
| vb            | 0.00142  |
| vb_q0         | 0.00579  |
| vb_q1         | 5.46e-05 |
| vb_q2         | 1.46e-05 |
| vb_q3         | 3.97e-06 |
----------------------------
----------------------------
| grad_norm     | 14.6     |
| lg_loss_scale | 15.8     |
| loss          | 0.0163   |
| loss_q0       | 0.0569   |
| loss_q1       | 0.00762  |
| loss_q2       | 0.00166  |
| loss_q3       | 0.000317 |
| mse           | 0.0147   |
| mse_q0        | 0.0502   |
| mse_q1        | 0.00756  |
| mse_q2        | 0.00165  |
| mse_q3        | 0.000313 |
| param_norm    | 347      |
| samples       | 2.18e+05 |
| step          | 850      |
| vb            | 0.00164  |
| vb_q0         | 0.00664  |
| vb_q1         | 5.62e-05 |
| vb_q2         | 1.47e-05 |
| vb_q3         | 3.88e-06 |
----------------------------
----------------------------
| grad_norm     | 23       |
| lg_loss_scale | 15.9     |
| loss          | 0.0223   |
| loss_q0       | 0.0801   |
| loss_q1       | 0.00756  |
| loss_q2       | 0.00167  |
| loss_q3       | 0.000333 |
| mse           | 0.0175   |
| mse_q0        | 0.0607   |
| mse_q1        | 0.00751  |
| mse_q2        | 0.00166  |
| mse_q3        | 0.000329 |
| param_norm    | 347      |
| samples       | 2.2e+05  |
| step          | 860      |
| vb            | 0.00483  |
| vb_q0         | 0.0194   |
| vb_q1         | 5.55e-05 |
| vb_q2         | 1.48e-05 |
| vb_q3         | 4.12e-06 |
----------------------------
----------------------------
| grad_norm     | 20       |
| lg_loss_scale | 15.9     |
| loss          | 0.0178   |
| loss_q0       | 0.0637   |
| loss_q1       | 0.00757  |
| loss_q2       | 0.00169  |
| loss_q3       | 0.000345 |
| mse           | 0.0151   |
| mse_q0        | 0.0528   |
| mse_q1        | 0.00752  |
| mse_q2        | 0.00167  |
| mse_q3        | 0.00034  |
| param_norm    | 347      |
| samples       | 2.23e+05 |
| step          | 870      |
| vb            | 0.00266  |
| vb_q0         | 0.011    |
| vb_q1         | 5.57e-05 |
| vb_q2         | 1.5e-05  |
| vb_q3         | 4.27e-06 |
----------------------------
----------------------------
| grad_norm     | 20.1     |
| lg_loss_scale | 15.9     |
| loss          | 0.019    |
| loss_q0       | 0.0686   |
| loss_q1       | 0.00744  |
| loss_q2       | 0.00167  |
| loss_q3       | 0.000324 |
| mse           | 0.0151   |
| mse_q0        | 0.0525   |
| mse_q1        | 0.00739  |
| mse_q2        | 0.00165  |
| mse_q3        | 0.00032  |
| param_norm    | 347      |
| samples       | 2.26e+05 |
| step          | 880      |
| vb            | 0.00393  |
| vb_q0         | 0.0161   |
| vb_q1         | 5.47e-05 |
| vb_q2         | 1.48e-05 |
| vb_q3         | 4.02e-06 |
----------------------------
----------------------------
| grad_norm     | 25.4     |
| lg_loss_scale | 15.9     |
| loss          | 0.0221   |
| loss_q0       | 0.0743   |
| loss_q1       | 0.00774  |
| loss_q2       | 0.00166  |
| loss_q3       | 0.00035  |
| mse           | 0.0183   |
| mse_q0        | 0.0599   |
| mse_q1        | 0.00768  |
| mse_q2        | 0.00165  |
| mse_q3        | 0.000346 |
| param_norm    | 347      |
| samples       | 2.28e+05 |
| step          | 890      |
| vb            | 0.00385  |
| vb_q0         | 0.0144   |
| vb_q1         | 5.69e-05 |
| vb_q2         | 1.48e-05 |
| vb_q3         | 4.35e-06 |
----------------------------
----------------------------
| grad_norm     | 20.9     |
| lg_loss_scale | 15.9     |
| loss          | 0.0196   |
| loss_q0       | 0.0702   |
| loss_q1       | 0.00775  |
| loss_q2       | 0.00169  |
| loss_q3       | 0.000356 |
| mse           | 0.016    |
| mse_q0        | 0.0556   |
| mse_q1        | 0.00769  |
| mse_q2        | 0.00168  |
| mse_q3        | 0.000351 |
| param_norm    | 347      |
| samples       | 2.31e+05 |
| step          | 900      |
| vb            | 0.00356  |
| vb_q0         | 0.0146   |
| vb_q1         | 5.71e-05 |
| vb_q2         | 1.51e-05 |
| vb_q3         | 4.42e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 13       |
| lg_loss_scale | 15.9     |
| loss          | 0.0194   |
| loss_q0       | 0.0697   |
| loss_q1       | 0.00747  |
| loss_q2       | 0.00171  |
| loss_q3       | 0.000314 |
| mse           | 0.0157   |
| mse_q0        | 0.0546   |
| mse_q1        | 0.00742  |
| mse_q2        | 0.00169  |
| mse_q3        | 0.00031  |
| param_norm    | 347      |
| samples       | 2.33e+05 |
| step          | 910      |
| vb            | 0.0037   |
| vb_q0         | 0.0152   |
| vb_q1         | 5.49e-05 |
| vb_q2         | 1.51e-05 |
| vb_q3         | 3.87e-06 |
----------------------------
----------------------------
| grad_norm     | 14.9     |
| lg_loss_scale | 15.9     |
| loss          | 0.0154   |
| loss_q0       | 0.0525   |
| loss_q1       | 0.00751  |
| loss_q2       | 0.00171  |
| loss_q3       | 0.000297 |
| mse           | 0.0139   |
| mse_q0        | 0.0466   |
| mse_q1        | 0.00746  |
| mse_q2        | 0.00169  |
| mse_q3        | 0.000293 |
| param_norm    | 347      |
| samples       | 2.36e+05 |
| step          | 920      |
| vb            | 0.00147  |
| vb_q0         | 0.0059   |
| vb_q1         | 5.53e-05 |
| vb_q2         | 1.51e-05 |
| vb_q3         | 3.69e-06 |
----------------------------
----------------------------
| grad_norm     | 20.4     |
| lg_loss_scale | 15.9     |
| loss          | 0.0183   |
| loss_q0       | 0.0608   |
| loss_q1       | 0.00718  |
| loss_q2       | 0.00169  |
| loss_q3       | 0.000307 |
| mse           | 0.0159   |
| mse_q0        | 0.0515   |
| mse_q1        | 0.00713  |
| mse_q2        | 0.00168  |
| mse_q3        | 0.000303 |
| param_norm    | 347      |
| samples       | 2.38e+05 |
| step          | 930      |
| vb            | 0.00246  |
| vb_q0         | 0.00928  |
| vb_q1         | 5.29e-05 |
| vb_q2         | 1.49e-05 |
| vb_q3         | 3.79e-06 |
----------------------------
----------------------------
| grad_norm     | 17.9     |
| lg_loss_scale | 15.9     |
| loss          | 0.019    |
| loss_q0       | 0.0688   |
| loss_q1       | 0.00761  |
| loss_q2       | 0.00165  |
| loss_q3       | 0.0003   |
| mse           | 0.0152   |
| mse_q0        | 0.0531   |
| mse_q1        | 0.00755  |
| mse_q2        | 0.00163  |
| mse_q3        | 0.000296 |
| param_norm    | 347      |
| samples       | 2.41e+05 |
| step          | 940      |
| vb            | 0.0038   |
| vb_q0         | 0.0157   |
| vb_q1         | 5.59e-05 |
| vb_q2         | 1.46e-05 |
| vb_q3         | 3.72e-06 |
----------------------------
----------------------------
| grad_norm     | 18.3     |
| lg_loss_scale | 15.9     |
| loss          | 0.0216   |
| loss_q0       | 0.0732   |
| loss_q1       | 0.00768  |
| loss_q2       | 0.00157  |
| loss_q3       | 0.000306 |
| mse           | 0.0172   |
| mse_q0        | 0.0565   |
| mse_q1        | 0.00762  |
| mse_q2        | 0.00156  |
| mse_q3        | 0.000303 |
| param_norm    | 347      |
| samples       | 2.43e+05 |
| step          | 950      |
| vb            | 0.00441  |
| vb_q0         | 0.0167   |
| vb_q1         | 5.64e-05 |
| vb_q2         | 1.4e-05  |
| vb_q3         | 3.76e-06 |
----------------------------
----------------------------
| grad_norm     | 16.4     |
| lg_loss_scale | 16       |
| loss          | 0.0214   |
| loss_q0       | 0.0767   |
| loss_q1       | 0.00726  |
| loss_q2       | 0.00159  |
| loss_q3       | 0.000296 |
| mse           | 0.0169   |
| mse_q0        | 0.0589   |
| mse_q1        | 0.00721  |
| mse_q2        | 0.00158  |
| mse_q3        | 0.000293 |
| param_norm    | 347      |
| samples       | 2.46e+05 |
| step          | 960      |
| vb            | 0.00447  |
| vb_q0         | 0.0178   |
| vb_q1         | 5.34e-05 |
| vb_q2         | 1.42e-05 |
| vb_q3         | 3.64e-06 |
----------------------------
----------------------------
| grad_norm     | 15.9     |
| lg_loss_scale | 16       |
| loss          | 0.0192   |
| loss_q0       | 0.0693   |
| loss_q1       | 0.00707  |
| loss_q2       | 0.00164  |
| loss_q3       | 0.000301 |
| mse           | 0.0152   |
| mse_q0        | 0.0528   |
| mse_q1        | 0.00702  |
| mse_q2        | 0.00163  |
| mse_q3        | 0.000297 |
| param_norm    | 347      |
| samples       | 2.49e+05 |
| step          | 970      |
| vb            | 0.00406  |
| vb_q0         | 0.0165   |
| vb_q1         | 5.2e-05  |
| vb_q2         | 1.46e-05 |
| vb_q3         | 3.71e-06 |
----------------------------
----------------------------
| grad_norm     | 19.5     |
| lg_loss_scale | 16       |
| loss          | 0.0173   |
| loss_q0       | 0.0615   |
| loss_q1       | 0.00736  |
| loss_q2       | 0.00154  |
| loss_q3       | 0.000299 |
| mse           | 0.015    |
| mse_q0        | 0.0521   |
| mse_q1        | 0.00731  |
| mse_q2        | 0.00152  |
| mse_q3        | 0.000296 |
| param_norm    | 347      |
| samples       | 2.51e+05 |
| step          | 980      |
| vb            | 0.00233  |
| vb_q0         | 0.00946  |
| vb_q1         | 5.41e-05 |
| vb_q2         | 1.37e-05 |
| vb_q3         | 3.72e-06 |
----------------------------
----------------------------
| grad_norm     | 15.8     |
| lg_loss_scale | 16       |
| loss          | 0.0187   |
| loss_q0       | 0.0636   |
| loss_q1       | 0.00758  |
| loss_q2       | 0.00162  |
| loss_q3       | 0.000297 |
| mse           | 0.0163   |
| mse_q0        | 0.0545   |
| mse_q1        | 0.00753  |
| mse_q2        | 0.00161  |
| mse_q3        | 0.000294 |
| param_norm    | 347      |
| samples       | 2.54e+05 |
| step          | 990      |
| vb            | 0.00235  |
| vb_q0         | 0.00906  |
| vb_q1         | 5.58e-05 |
| vb_q2         | 1.44e-05 |
| vb_q3         | 3.68e-06 |
----------------------------
----------------------------
| grad_norm     | 19.7     |
| lg_loss_scale | 16       |
| loss          | 0.0194   |
| loss_q0       | 0.0678   |
| loss_q1       | 0.00769  |
| loss_q2       | 0.00159  |
| loss_q3       | 0.000309 |
| mse           | 0.016    |
| mse_q0        | 0.0541   |
| mse_q1        | 0.00763  |
| mse_q2        | 0.00158  |
| mse_q3        | 0.000305 |
| param_norm    | 347      |
| samples       | 2.56e+05 |
| step          | 1e+03    |
| vb            | 0.00347  |
| vb_q0         | 0.0137   |
| vb_q1         | 5.66e-05 |
| vb_q2         | 1.42e-05 |
| vb_q3         | 3.81e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 17.8     |
| lg_loss_scale | 16       |
| loss          | 0.0168   |
| loss_q0       | 0.0586   |
| loss_q1       | 0.00739  |
| loss_q2       | 0.0016   |
| loss_q3       | 0.000283 |
| mse           | 0.0152   |
| mse_q0        | 0.0523   |
| mse_q1        | 0.00734  |
| mse_q2        | 0.00158  |
| mse_q3        | 0.00028  |
| param_norm    | 347      |
| samples       | 2.59e+05 |
| step          | 1.01e+03 |
| vb            | 0.00157  |
| vb_q0         | 0.0063   |
| vb_q1         | 5.45e-05 |
| vb_q2         | 1.41e-05 |
| vb_q3         | 3.53e-06 |
----------------------------
----------------------------
| grad_norm     | 20.8     |
| lg_loss_scale | 16       |
| loss          | 0.0174   |
| loss_q0       | 0.0624   |
| loss_q1       | 0.00752  |
| loss_q2       | 0.00165  |
| loss_q3       | 0.000307 |
| mse           | 0.0149   |
| mse_q0        | 0.0524   |
| mse_q1        | 0.00746  |
| mse_q2        | 0.00163  |
| mse_q3        | 0.000304 |
| param_norm    | 347      |
| samples       | 2.61e+05 |
| step          | 1.02e+03 |
| vb            | 0.00242  |
| vb_q0         | 0.01     |
| vb_q1         | 5.54e-05 |
| vb_q2         | 1.46e-05 |
| vb_q3         | 3.79e-06 |
----------------------------
----------------------------
| grad_norm     | 12.2     |
| lg_loss_scale | 16       |
| loss          | 0.0195   |
| loss_q0       | 0.0683   |
| loss_q1       | 0.00723  |
| loss_q2       | 0.00158  |
| loss_q3       | 0.000288 |
| mse           | 0.0154   |
| mse_q0        | 0.0524   |
| mse_q1        | 0.00718  |
| mse_q2        | 0.00157  |
| mse_q3        | 0.000284 |
| param_norm    | 347      |
| samples       | 2.64e+05 |
| step          | 1.03e+03 |
| vb            | 0.00403  |
| vb_q0         | 0.016    |
| vb_q1         | 5.32e-05 |
| vb_q2         | 1.41e-05 |
| vb_q3         | 3.53e-06 |
----------------------------
----------------------------
| grad_norm     | 14.4     |
| lg_loss_scale | 16       |
| loss          | 0.0195   |
| loss_q0       | 0.0675   |
| loss_q1       | 0.00716  |
| loss_q2       | 0.00159  |
| loss_q3       | 0.000283 |
| mse           | 0.0162   |
| mse_q0        | 0.0548   |
| mse_q1        | 0.00711  |
| mse_q2        | 0.00157  |
| mse_q3        | 0.00028  |
| param_norm    | 347      |
| samples       | 2.66e+05 |
| step          | 1.04e+03 |
| vb            | 0.00326  |
| vb_q0         | 0.0127   |
| vb_q1         | 5.28e-05 |
| vb_q2         | 1.41e-05 |
| vb_q3         | 3.5e-06  |
----------------------------
----------------------------
| grad_norm     | 22       |
| lg_loss_scale | 16       |
| loss          | 0.0191   |
| loss_q0       | 0.0698   |
| loss_q1       | 0.00758  |
| loss_q2       | 0.00161  |
| loss_q3       | 0.00031  |
| mse           | 0.0163   |
| mse_q0        | 0.0582   |
| mse_q1        | 0.00752  |
| mse_q2        | 0.0016   |
| mse_q3        | 0.000306 |
| param_norm    | 347      |
| samples       | 2.69e+05 |
| step          | 1.05e+03 |
| vb            | 0.00277  |
| vb_q0         | 0.0116   |
| vb_q1         | 5.57e-05 |
| vb_q2         | 1.44e-05 |
| vb_q3         | 3.84e-06 |
----------------------------
----------------------------
| grad_norm     | 25.6     |
| lg_loss_scale | 16.1     |
| loss          | 0.0173   |
| loss_q0       | 0.0607   |
| loss_q1       | 0.00739  |
| loss_q2       | 0.00169  |
| loss_q3       | 0.000315 |
| mse           | 0.0156   |
| mse_q0        | 0.0537   |
| mse_q1        | 0.00734  |
| mse_q2        | 0.00168  |
| mse_q3        | 0.000311 |
| param_norm    | 347      |
| samples       | 2.72e+05 |
| step          | 1.06e+03 |
| vb            | 0.00172  |
| vb_q0         | 0.00693  |
| vb_q1         | 5.44e-05 |
| vb_q2         | 1.5e-05  |
| vb_q3         | 3.91e-06 |
----------------------------
----------------------------
| grad_norm     | 23.6     |
| lg_loss_scale | 16.1     |
| loss          | 0.0175   |
| loss_q0       | 0.0597   |
| loss_q1       | 0.00727  |
| loss_q2       | 0.00166  |
| loss_q3       | 0.000312 |
| mse           | 0.0156   |
| mse_q0        | 0.0526   |
| mse_q1        | 0.00722  |
| mse_q2        | 0.00164  |
| mse_q3        | 0.000308 |
| param_norm    | 348      |
| samples       | 2.74e+05 |
| step          | 1.07e+03 |
| vb            | 0.00184  |
| vb_q0         | 0.00713  |
| vb_q1         | 5.36e-05 |
| vb_q2         | 1.47e-05 |
| vb_q3         | 3.86e-06 |
----------------------------
----------------------------
| grad_norm     | 16.3     |
| lg_loss_scale | 16.1     |
| loss          | 0.0197   |
| loss_q0       | 0.068    |
| loss_q1       | 0.00744  |
| loss_q2       | 0.00159  |
| loss_q3       | 0.000294 |
| mse           | 0.0163   |
| mse_q0        | 0.0546   |
| mse_q1        | 0.00739  |
| mse_q2        | 0.00157  |
| mse_q3        | 0.00029  |
| param_norm    | 348      |
| samples       | 2.77e+05 |
| step          | 1.08e+03 |
| vb            | 0.00344  |
| vb_q0         | 0.0134   |
| vb_q1         | 5.48e-05 |
| vb_q2         | 1.4e-05  |
| vb_q3         | 3.63e-06 |
----------------------------
----------------------------
| grad_norm     | 18.2     |
| lg_loss_scale | 16.1     |
| loss          | 0.0221   |
| loss_q0       | 0.0742   |
| loss_q1       | 0.00732  |
| loss_q2       | 0.00158  |
| loss_q3       | 0.000295 |
| mse           | 0.0177   |
| mse_q0        | 0.0579   |
| mse_q1        | 0.00727  |
| mse_q2        | 0.00156  |
| mse_q3        | 0.000291 |
| param_norm    | 348      |
| samples       | 2.79e+05 |
| step          | 1.09e+03 |
| vb            | 0.00438  |
| vb_q0         | 0.0164   |
| vb_q1         | 5.38e-05 |
| vb_q2         | 1.41e-05 |
| vb_q3         | 3.66e-06 |
----------------------------
----------------------------
| grad_norm     | 26.4     |
| lg_loss_scale | 16.1     |
| loss          | 0.0183   |
| loss_q0       | 0.0612   |
| loss_q1       | 0.00748  |
| loss_q2       | 0.00165  |
| loss_q3       | 0.000332 |
| mse           | 0.0157   |
| mse_q0        | 0.0511   |
| mse_q1        | 0.00742  |
| mse_q2        | 0.00164  |
| mse_q3        | 0.000328 |
| param_norm    | 348      |
| samples       | 2.82e+05 |
| step          | 1.1e+03  |
| vb            | 0.00265  |
| vb_q0         | 0.0101   |
| vb_q1         | 5.49e-05 |
| vb_q2         | 1.46e-05 |
| vb_q3         | 4.12e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 18.2     |
| lg_loss_scale | 16.1     |
| loss          | 0.0203   |
| loss_q0       | 0.0705   |
| loss_q1       | 0.00743  |
| loss_q2       | 0.00162  |
| loss_q3       | 0.000306 |
| mse           | 0.0162   |
| mse_q0        | 0.0544   |
| mse_q1        | 0.00738  |
| mse_q2        | 0.00161  |
| mse_q3        | 0.000302 |
| param_norm    | 348      |
| samples       | 2.84e+05 |
| step          | 1.11e+03 |
| vb            | 0.00409  |
| vb_q0         | 0.0161   |
| vb_q1         | 5.47e-05 |
| vb_q2         | 1.44e-05 |
| vb_q3         | 3.76e-06 |
----------------------------
----------------------------
| grad_norm     | 13.4     |
| lg_loss_scale | 16.1     |
| loss          | 0.0186   |
| loss_q0       | 0.062    |
| loss_q1       | 0.00713  |
| loss_q2       | 0.00155  |
| loss_q3       | 0.000275 |
| mse           | 0.0166   |
| mse_q0        | 0.0546   |
| mse_q1        | 0.00708  |
| mse_q2        | 0.00154  |
| mse_q3        | 0.000272 |
| param_norm    | 348      |
| samples       | 2.87e+05 |
| step          | 1.12e+03 |
| vb            | 0.00196  |
| vb_q0         | 0.00737  |
| vb_q1         | 5.24e-05 |
| vb_q2         | 1.38e-05 |
| vb_q3         | 3.41e-06 |
----------------------------
----------------------------
| grad_norm     | 15.4     |
| lg_loss_scale | 16.1     |
| loss          | 0.0184   |
| loss_q0       | 0.0635   |
| loss_q1       | 0.00727  |
| loss_q2       | 0.00159  |
| loss_q3       | 0.00028  |
| mse           | 0.0152   |
| mse_q0        | 0.051    |
| mse_q1        | 0.00721  |
| mse_q2        | 0.00158  |
| mse_q3        | 0.000277 |
| param_norm    | 348      |
| samples       | 2.9e+05  |
| step          | 1.13e+03 |
| vb            | 0.00319  |
| vb_q0         | 0.0125   |
| vb_q1         | 5.35e-05 |
| vb_q2         | 1.42e-05 |
| vb_q3         | 3.46e-06 |
----------------------------
----------------------------
| grad_norm     | 16.5     |
| lg_loss_scale | 16.1     |
| loss          | 0.0176   |
| loss_q0       | 0.0589   |
| loss_q1       | 0.00713  |
| loss_q2       | 0.00158  |
| loss_q3       | 0.000279 |
| mse           | 0.0156   |
| mse_q0        | 0.0512   |
| mse_q1        | 0.00708  |
| mse_q2        | 0.00157  |
| mse_q3        | 0.000275 |
| param_norm    | 348      |
| samples       | 2.92e+05 |
| step          | 1.14e+03 |
| vb            | 0.00202  |
| vb_q0         | 0.00767  |
| vb_q1         | 5.25e-05 |
| vb_q2         | 1.41e-05 |
| vb_q3         | 3.44e-06 |
----------------------------
----------------------------
| grad_norm     | 17.2     |
| lg_loss_scale | 16.1     |
| loss          | 0.0233   |
| loss_q0       | 0.0825   |
| loss_q1       | 0.00707  |
| loss_q2       | 0.00163  |
| loss_q3       | 0.000299 |
| mse           | 0.0165   |
| mse_q0        | 0.0559   |
| mse_q1        | 0.00702  |
| mse_q2        | 0.00161  |
| mse_q3        | 0.000295 |
| param_norm    | 348      |
| samples       | 2.95e+05 |
| step          | 1.15e+03 |
| vb            | 0.00682  |
| vb_q0         | 0.0267   |
| vb_q1         | 5.2e-05  |
| vb_q2         | 1.44e-05 |
| vb_q3         | 3.69e-06 |
----------------------------
----------------------------
| grad_norm     | 20.3     |
| lg_loss_scale | 16.2     |
| loss          | 0.0179   |
| loss_q0       | 0.0599   |
| loss_q1       | 0.00741  |
| loss_q2       | 0.00155  |
| loss_q3       | 0.000287 |
| mse           | 0.0154   |
| mse_q0        | 0.0504   |
| mse_q1        | 0.00736  |
| mse_q2        | 0.00154  |
| mse_q3        | 0.000284 |
| param_norm    | 348      |
| samples       | 2.97e+05 |
| step          | 1.16e+03 |
| vb            | 0.00251  |
| vb_q0         | 0.0095   |
| vb_q1         | 5.45e-05 |
| vb_q2         | 1.39e-05 |
| vb_q3         | 3.58e-06 |
----------------------------
----------------------------
| grad_norm     | 13.5     |
| lg_loss_scale | 16.2     |
| loss          | 0.0159   |
| loss_q0       | 0.0544   |
| loss_q1       | 0.00735  |
| loss_q2       | 0.00164  |
| loss_q3       | 0.000274 |
| mse           | 0.0144   |
| mse_q0        | 0.0485   |
| mse_q1        | 0.0073   |
| mse_q2        | 0.00163  |
| mse_q3        | 0.000271 |
| param_norm    | 348      |
| samples       | 3e+05    |
| step          | 1.17e+03 |
| vb            | 0.00151  |
| vb_q0         | 0.00594  |
| vb_q1         | 5.4e-05  |
| vb_q2         | 1.45e-05 |
| vb_q3         | 3.4e-06  |
----------------------------
----------------------------
| grad_norm     | 12.2     |
| lg_loss_scale | 16.2     |
| loss          | 0.0175   |
| loss_q0       | 0.0614   |
| loss_q1       | 0.0072   |
| loss_q2       | 0.00155  |
| loss_q3       | 0.000272 |
| mse           | 0.015    |
| mse_q0        | 0.0514   |
| mse_q1        | 0.00714  |
| mse_q2        | 0.00154  |
| mse_q3        | 0.000268 |
| param_norm    | 348      |
| samples       | 3.02e+05 |
| step          | 1.18e+03 |
| vb            | 0.00252  |
| vb_q0         | 0.0101   |
| vb_q1         | 5.29e-05 |
| vb_q2         | 1.38e-05 |
| vb_q3         | 3.35e-06 |
----------------------------
----------------------------
| grad_norm     | 8.96     |
| lg_loss_scale | 16.2     |
| loss          | 0.0181   |
| loss_q0       | 0.0626   |
| loss_q1       | 0.00722  |
| loss_q2       | 0.00155  |
| loss_q3       | 0.00026  |
| mse           | 0.0153   |
| mse_q0        | 0.0515   |
| mse_q1        | 0.00717  |
| mse_q2        | 0.00154  |
| mse_q3        | 0.000257 |
| param_norm    | 348      |
| samples       | 3.05e+05 |
| step          | 1.19e+03 |
| vb            | 0.00282  |
| vb_q0         | 0.0111   |
| vb_q1         | 5.3e-05  |
| vb_q2         | 1.38e-05 |
| vb_q3         | 3.2e-06  |
----------------------------
----------------------------
| grad_norm     | 21.3     |
| lg_loss_scale | 16.2     |
| loss          | 0.0179   |
| loss_q0       | 0.0626   |
| loss_q1       | 0.00713  |
| loss_q2       | 0.00163  |
| loss_q3       | 0.000298 |
| mse           | 0.0151   |
| mse_q0        | 0.0516   |
| mse_q1        | 0.00707  |
| mse_q2        | 0.00161  |
| mse_q3        | 0.000295 |
| param_norm    | 348      |
| samples       | 3.07e+05 |
| step          | 1.2e+03  |
| vb            | 0.00278  |
| vb_q0         | 0.011    |
| vb_q1         | 5.24e-05 |
| vb_q2         | 1.44e-05 |
| vb_q3         | 3.69e-06 |
----------------------------
saving model 0...
saving model 0.9999...
----------------------------
| grad_norm     | 15       |
| lg_loss_scale | 16.2     |
| loss          | 0.0187   |
| loss_q0       | 0.0651   |
| loss_q1       | 0.00737  |
| loss_q2       | 0.00162  |
| loss_q3       | 0.000291 |
| mse           | 0.0159   |
| mse_q0        | 0.0541   |
| mse_q1        | 0.00731  |
| mse_q2        | 0.00161  |
| mse_q3        | 0.000288 |
| param_norm    | 348      |
| samples       | 3.1e+05  |
| step          | 1.21e+03 |
| vb            | 0.00279  |
| vb_q0         | 0.011    |
| vb_q1         | 5.41e-05 |
| vb_q2         | 1.44e-05 |
| vb_q3         | 3.6e-06  |
----------------------------
----------------------------
| grad_norm     | 14.2     |
| lg_loss_scale | 16.2     |
| loss          | 0.0173   |
| loss_q0       | 0.0625   |
| loss_q1       | 0.00712  |
| loss_q2       | 0.00158  |
| loss_q3       | 0.00029  |
| mse           | 0.0158   |
| mse_q0        | 0.0562   |
| mse_q1        | 0.00707  |
| mse_q2        | 0.00157  |
| mse_q3        | 0.000286 |
| param_norm    | 348      |
| samples       | 3.13e+05 |
| step          | 1.22e+03 |
| vb            | 0.00154  |
| vb_q0         | 0.00631  |
| vb_q1         | 5.23e-05 |
| vb_q2         | 1.41e-05 |
| vb_q3         | 3.57e-06 |
----------------------------
----------------------------
| grad_norm     | 17.5     |
| lg_loss_scale | 16.2     |
| loss          | 0.021    |
| loss_q0       | 0.0721   |
| loss_q1       | 0.00745  |
| loss_q2       | 0.00158  |
| loss_q3       | 0.000285 |
| mse           | 0.0167   |
| mse_q0        | 0.0557   |
| mse_q1        | 0.0074   |
| mse_q2        | 0.00157  |
| mse_q3        | 0.000281 |
| param_norm    | 348      |
| samples       | 3.15e+05 |
| step          | 1.23e+03 |
| vb            | 0.00427  |
| vb_q0         | 0.0164   |
| vb_q1         | 5.47e-05 |
| vb_q2         | 1.4e-05  |
| vb_q3         | 3.52e-06 |
----------------------------
----------------------------
| grad_norm     | 15       |
| lg_loss_scale | 16.2     |
| loss          | 0.0174   |
| loss_q0       | 0.0616   |
| loss_q1       | 0.00706  |
| loss_q2       | 0.00157  |
| loss_q3       | 0.000292 |
| mse           | 0.0153   |
| mse_q0        | 0.0533   |
| mse_q1        | 0.00701  |
| mse_q2        | 0.00156  |
| mse_q3        | 0.000289 |
| param_norm    | 348      |
| samples       | 3.18e+05 |
| step          | 1.24e+03 |
| vb            | 0.00205  |
| vb_q0         | 0.0083   |
| vb_q1         | 5.19e-05 |
| vb_q2         | 1.4e-05  |
| vb_q3         | 3.62e-06 |
----------------------------
----------------------------
| grad_norm     | 14.8     |
| lg_loss_scale | 16.2     |
| loss          | 0.0166   |
| loss_q0       | 0.0594   |
| loss_q1       | 0.00717  |
| loss_q2       | 0.00162  |
| loss_q3       | 0.000279 |
| mse           | 0.0143   |
| mse_q0        | 0.0498   |
| mse_q1        | 0.00712  |
| mse_q2        | 0.00161  |
| mse_q3        | 0.000276 |
| param_norm    | 348      |
| samples       | 3.2e+05  |
| step          | 1.25e+03 |
| vb            | 0.00232  |
| vb_q0         | 0.00957  |
| vb_q1         | 5.28e-05 |
| vb_q2         | 1.44e-05 |
| vb_q3         | 3.46e-06 |
----------------------------
----------------------------
| grad_norm     | 14       |
| lg_loss_scale | 16.3     |
| loss          | 0.0222   |
| loss_q0       | 0.0798   |
| loss_q1       | 0.0074   |
| loss_q2       | 0.0015   |
| loss_q3       | 0.000287 |
| mse           | 0.0171   |
| mse_q0        | 0.0595   |
| mse_q1        | 0.00735  |
| mse_q2        | 0.00149  |
| mse_q3        | 0.000284 |
| param_norm    | 348      |
| samples       | 3.23e+05 |
| step          | 1.26e+03 |
| vb            | 0.00509  |
| vb_q0         | 0.0203   |
| vb_q1         | 5.44e-05 |
| vb_q2         | 1.34e-05 |
| vb_q3         | 3.53e-06 |
----------------------------
----------------------------
| grad_norm     | 17.2     |
| lg_loss_scale | 16.3     |
| loss          | 0.0183   |
| loss_q0       | 0.0628   |
| loss_q1       | 0.00721  |
| loss_q2       | 0.00164  |
| loss_q3       | 0.000275 |
| mse           | 0.0162   |
| mse_q0        | 0.0544   |
| mse_q1        | 0.00716  |
| mse_q2        | 0.00163  |
| mse_q3        | 0.000272 |
| param_norm    | 348      |
| samples       | 3.25e+05 |
| step          | 1.27e+03 |
| vb            | 0.00217  |
| vb_q0         | 0.00847  |
| vb_q1         | 5.3e-05  |
| vb_q2         | 1.45e-05 |
| vb_q3         | 3.4e-06  |
----------------------------
----------------------------
| grad_norm     | 18.1     |
| lg_loss_scale | 16.3     |
| loss          | 0.0202   |
| loss_q0       | 0.075    |
| loss_q1       | 0.0071   |
| loss_q2       | 0.00164  |
| loss_q3       | 0.000283 |
| mse           | 0.0159   |
| mse_q0        | 0.0567   |
| mse_q1        | 0.00705  |
| mse_q2        | 0.00162  |
| mse_q3        | 0.00028  |
| param_norm    | 348      |
| samples       | 3.28e+05 |
| step          | 1.28e+03 |
| vb            | 0.00439  |
| vb_q0         | 0.0183   |
| vb_q1         | 5.22e-05 |
| vb_q2         | 1.44e-05 |
| vb_q3         | 3.49e-06 |
----------------------------
----------------------------
| grad_norm     | 15.5     |
| lg_loss_scale | 16.3     |
| loss          | 0.0184   |
| loss_q0       | 0.0628   |
| loss_q1       | 0.00725  |
| loss_q2       | 0.00153  |
| loss_q3       | 0.000279 |
| mse           | 0.0163   |
| mse_q0        | 0.0547   |
| mse_q1        | 0.0072   |
| mse_q2        | 0.00152  |
| mse_q3        | 0.000276 |
| param_norm    | 348      |
| samples       | 3.3e+05  |
| step          | 1.29e+03 |
| vb            | 0.00208  |
| vb_q0         | 0.00805  |
| vb_q1         | 5.33e-05 |
| vb_q2         | 1.36e-05 |
| vb_q3         | 3.43e-06 |
----------------------------
